{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPaeRDI7sUUdCLynbjWBIMI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Gerekli Kütüphanelerin Yüklenmesi"],"metadata":{"id":"5yiuPk_5iFAQ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ghb5Dr8uiA2r"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from tensorflow.python.framework import ops\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import sys\n","import os\n","import scipy.io.wavfile as sci_wav\n","import random"]},{"cell_type":"markdown","source":["Kullancılacak dosyaların yolları belirlenir"],"metadata":{"id":"zTPVobkkiXFu"}},{"cell_type":"code","source":["ROOT_DIR = \"\"\n","CSV_PATH = \"\""],"metadata":{"id":"zAMYt_vXiatA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ses dosyalarının okunması ve sistem üzerinden çağırılması"],"metadata":{"id":"laA1dfjxiikd"}},{"cell_type":"code","source":["def read_wav_files(wav_files):\n","  if not isinstance(wav_files, list):\n","    wav_files = [wav_files]\n","  return [sci_wav.read(ROOT_DIR+f)[1] for f in wav_files]\n","\n","def get_trunk(_X, idx,sample_len, rand_offset=False):\n","  randint = np.random.randint(10000) if rand_offset is True else 0\n","  start_idx = (idx * sample_len + randint) % len(_X)\n","  end_idx = ((idx+1)*sample_len + randint) % len(_X)\n","  if end_idx > start_idx:\n","    return _X[start_idx:end_idx]\n","  else:\n","    return np.concatenate([_X[start_idx:], _X[:end_idx]])\n","\n","def get_augmented_trunk(_X, idx,sample_len, added_samples=0):\n","  X = get_trunk(_X, idx, sample_len)\n","\n","  for _ in range(added_samples):\n","    ridx = np.random.randint(len(_X))\n","    X = X + get_trunk(_X, ridx, sample_len)\n","  return X"],"metadata":{"id":"bdT5fTR5ik8y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sınıflandırma işleminin daha iyi olabilmesi için ses dosyaları çoğaltılır"],"metadata":{"id":"04HgGKapjsxc"}},{"cell_type":"code","source":["def dataset_gen(is_train = True, batch_shape(20,16000), sample_augmentation = 0):\n","  s_per_batch = batch_shape[0]\n","  s_len = batch_shape[1]\n","\n","  X_cat = dataset['train_cat'] if is_train else dataset ['test_cat']\n","  X_dog = dataset['traind_dog'] if is_train else dataset ['test_dog']\n","\n","  y_batch = np.zeros(s_per_batch)\n","  X_batch = np.zeros(batch_shape)\n","\n","  nbatch = int(max(len(X_cat), len(X_cat)) / s_len)\n","  perms = [list(enumerate([i]*nbatch)) for i in range(2)]\n","  perms = sum(perms, [])\n","  random.shuffle(perms)\n","\n","  while len(perms) > s_per_batch:\n","\n","    for bidx in range(s_per_batch):\n","      perm, _y = perms.pop()\n","      y_batch[bidx] = _y\n","\n","      _X = X_cat if _y == 0 else X_dog\n","\n","      if is_train:\n","        X_batch[bidx] = get_augmented_trunk(_X, idx = perm,sample_len = s_len, added_samples = sample_augmentation)\n","      else:\n","        X_batch[bidx] = get_trunk(_X, perm, s_len)\n","\n","    yield (X_batch.reshape(s_per_batch,s_len,1),\n","           y_batch.reshape(-1,1))"],"metadata":{"id":"4BCPimJzjsfe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Veriseti  hazırlanır"],"metadata":{"id":"KeLy3Mo9lgPj"}},{"cell_type":"code","source":["def load_dataset (dataframe):\n","  df = dataframe\n","\n","  dataset{}\n","  for k in ['train_cat','train_dog','test_cat','test_dog']:\n","    v = list(df[k].dropna())\n","    v = read_wav_files(v)\n","    v = np.concatenate(v).astype('float32')\n","\n","    if k == 'train_cat':\n","      dog_std = dog_mean = 0\n","      cat_std = cat_mean = v.std() , x.mean()\n","    elif k == 'train_dog':\n","      dog_std,dog_mean = v.std() , v.mean()\n","\n","    std, mean = (cat_std,cat_mean) if 'cat' in k else (dog_std,dog_mean)\n","    v = (v - mean) / std\n","    dataset[k] = v\n","    print('Loaded {} with {} sec of audio'.format(k,len(v)/16000))\n","\n","  return dataset\n","\n","ddf = pd.read_csv(CSV_PATH)\n","dataset = load_dataset(df)\n"],"metadata":{"id":"JicS8bNsliwW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Gerekli sabitler ayarlanır ve ağ modeli belirlenir"],"metadata":{"id":"cnuC2rsqmoQj"}},{"cell_type":"code","source":["batch_size = 512\n","num_data_points = 16000\n","n_augment = 10\n","\n","from tensorflow.keras import backend as K\n","K.clear_session()\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Embedding, BatchNormalization, Conv1D, MaxPooling1D, GlobalAveragePooling1D\n","from tensorflow.keras.optimizers import Adam\n","\n","model = Sequential()\n","\n","model.add(Conv1D(20, 4, strides= 2, activation='relu', input_shape=(num_data_points,1)))\n","model.add(BatchNormalization())\n","\n","model.add(Conv1D(20, 4, strides= 2, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(2))\n","\n","model.add(Conv1D(40, 4, strides= 2, activation='relu'))\n","model.add(BatchNormalization())\n","\n","model.add(Conv1D(40, 4, strides= 2, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling1D(2))\n","\n","model.add(Conv1D(80, 4, strides= 2, activation='relu'))\n","model.add(BatchNormalization())\n","\n","model.add(Conv1D(80, 4, strides= 2, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(GlobalAveragePooling1D())\n","\n","model.add(Dense(256))\n","model.add(BatchNormalization())\n","\n","model.add(Dropout(0.5))\n","model.add(Dense(256))\n","model.add(BatchNormalization())\n","\n","model.add(Dropout(0.5))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.summary()"],"metadata":{"id":"hKN9s7wLmru6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model derlenir ve eğitim işlemi gerçekleştirilir."],"metadata":{"id":"VJ_TU-KIouDX"}},{"cell_type":"code","source":["NUM_EPOCHS = 50\n","adam_ooptimizer = Adam(decay=1e-3)\n","model.compile(loss = 'binary_crossentropy',optimizer = adam_optimizer, metrics= ['accuracy'])\n","\n","NUM_EPOCHS = 50\n","\n","train_loss = []\n","val_loss= []\n","train_acc = []\n","val_acc = []\n","\n","for epochs in range(NUM_EPOCHS):\n","  train_gen = dataset_gen(is_train = True, batch_shape=(batch_size,num_data_points), sample_augmentation = n_augment)\n","\n","  for batch_x, batch_y in train_gen:\n","    history = model.fit(batch_x,batch_y,epochs=1,validation_split=0.2)\n","    train_loss.extend(history.history['loss'])\n","    val_loss.extend(history.history['val_loss'])\n","    train_acc.extend(history.history['accuracy'])\n","    val_acc.extend(history.history['val_accuracy'])"],"metadata":{"id":"647NUib8ownx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sistemin başarımı ve kayıpları grafik üstünde görelim"],"metadata":{"id":"dZZKvLhZpl3Z"}},{"cell_type":"code","source":["fig = plt.figure(figsize=(15,8))\n","ax = fig.add_subplot(111)\n","ax.plot(train_loss, label = 'train_loss')\n","ax.plot(val_loss, label = 'val_loss',color='green')\n","plt.legend()\n","plt.title(\"Log Loss\")\n","plt.show()\n","\n","fig = plt.figure(figsize=(15,8))\n","ax = fig.add_subplot(111)\n","ax.plot(train_acc, label = 'train_acc')\n","ax.plot(val_acc, label = 'val_acc',color='green')\n","plt.legend()\n","plt.title(\"Accuracy\")\n","plt.show()"],"metadata":{"id":"OT8lG1QapohV"},"execution_count":null,"outputs":[]}]}